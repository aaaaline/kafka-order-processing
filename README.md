# Sistema de Processamento de Pedidos com Apache Kafka

Este projeto demonstra uma arquitetura de microsservi√ßos simples para processamento de pedidos em uma plataforma de com√©rcio eletr√¥nico, utilizando Apache Kafka como backbone de mensageria para comunica√ß√£o ass√≠ncrona entre os servi√ßos.

## Integrantes do Grupo

* **Aline Lima** - **202201681**
* **Stephany Milhomem** - **202201714**

## 1. Vis√£o Geral do Projeto

O sistema √© composto por tr√™s servi√ßos principais (simulados) e uma infraestrutura de suporte:

* **Order-Service (Produtor):**
    * Servi√ßo Spring Boot respons√°vel por receber novos pedidos via uma API REST (`POST /orders`).
    * Gera um UUID para o pedido, registra um timestamp e persiste a lista de itens no banco de dados (PostgreSQL).
    * Publica o evento do pedido completo em um t√≥pico Kafka chamado `orders`.
* **Inventory-Service (Consumidor + Produtor):**
    * Servi√ßo Spring Boot que consome mensagens do t√≥pico `orders`.
    * Simula a reserva de estoque para os produtos do pedido (verificando a disponibilidade, mas sem persistir a altera√ß√£o de estoque neste exemplo).
    * Publica o resultado da reserva (sucesso ou falha por falta de estoque) em um novo t√≥pico Kafka chamado `inventory-events`.
* **Notification-Service (Consumidor):**
    * Servi√ßo Spring Boot que consome mensagens do t√≥pico `inventory-events`.
    * Registra no console uma notifica√ß√£o simulada (e-mails/SMS) ao cliente com base no status do pedido (confirmado ou falha no estoque).
    * Exp√µe um endpoint REST (`GET /notifications/latest`) para o frontend buscar a √∫ltima notifica√ß√£o processada.
* **Frontend (Aplica√ß√£o React com Ant Design):**
    * Uma interface de usu√°rio simples para permitir a cria√ß√£o e envio de novos pedidos ao Order-Service.
    * Exibe notifica√ß√µes em tempo real sobre o status do pedido (reserva de estoque) buscando informa√ß√µes do Notification-Service.
* **Infraestrutura de Mensageria e Banco de Dados (Docker Compose):**
    * **Apache Kafka:** O broker de mensagens distribu√≠do, essencial para a comunica√ß√£o ass√≠ncrona.
    * **Apache ZooKeeper:** Gerencia o estado e a coordena√ß√£o do cluster Kafka.
    * **PostgreSQL:** Banco de dados relacional para persistir informa√ß√µes de pedidos e produtos.
    * **pgAdmin:** Ferramenta de administra√ß√£o gr√°fica para PostgreSQL, √∫til para visualizar o banco de dados.
    * **Kafka UI:** Interface web para monitorar e gerenciar t√≥picos, produtores e consumidores Kafka.

## 2. Requisitos Funcionais (RFs)

* **RF-1 (T√≥picos Kafka):** Os t√≥picos `orders` e `inventory-events` s√£o criados no broker Kafka via linha de comando (`kafka-topics.sh`).
* **RF-2 (Order-Service API):** O Order-Service exp√µe uma REST API (`POST /orders`) que gera um UUID para o pedido, um timestamp de cria√ß√£o, persiste no banco de dados e publica o pedido completo no t√≥pico `orders` do Kafka.
* **RF-3 (Inventory-Service):** O Inventory-Service processa mensagens do t√≥pico `orders`, simula a reserva de estoque (verifica a quantidade dispon√≠vel dos produtos no banco de dados) e publica o resultado (sucesso ou falha por estoque insuficiente) no t√≥pico `inventory-events`.
* **RF-4 (Notification-Service):** O Notification-Service l√™ os eventos do t√≥pico `inventory-events` e registra no console uma notifica√ß√£o simulada (e-mail/SMS) para o cliente. Ele tamb√©m disponibiliza a √∫ltima notifica√ß√£o via API REST para o frontend.

## 3. Como Clonar e Executar a Solu√ß√£o

Siga os passos abaixo para colocar o sistema em funcionamento.

### Pr√©-requisitos:

* **Git:** Para clonar o reposit√≥rio.
* **Docker & Docker Compose:** Para rodar a infraestrutura (Kafka, ZooKeeper, PostgreSQL, pgAdmin, Kafka UI).
* **Java Development Kit (JDK) 17+:** Para compilar e rodar os backends Spring Boot.
* **Maven:** Ferramenta de automa√ß√£o de build para os projetos Java.
* **Node.js & npm:** Para rodar o frontend React (vers√£o 18.x ou superior recomendada).

### Passos para Configura√ß√£o e Execu√ß√£o:

1.  **Clone o Reposit√≥rio:**
    Abra seu terminal e execute:
    ```bash
    git clone [https://github.com/aaaaline/kafka-order-processing/](https://github.com/aaaaline/kafka-order-processing/)
    cd kafka-order-processing/
    ```

2.  **Inicie a Infraestrutura de Suporte (Docker Compose):**
    Na raiz do projeto (`kafka-order-processing/`), onde est√° o `docker-compose.yml`, execute:
    ```bash
    sudo docker-compose up -d
    ```
    Isso iniciar√° o ZooKeeper, Kafka, PostgreSQL, pgAdmin e Kafka UI em segundo plano. Aguarde alguns segundos para que todos os servi√ßos estejam completamente inicializados.

3.  **Crie e Popule o Banco de Dados (PostgreSQL):**

    * **Acesse o pgAdmin:** Abra seu navegador e v√° para `http://localhost:5050`. Fa√ßa login com o Email: `admin@admin.com` e Senha: `admin`.
    * **Conecte-se ao Servidor PostgreSQL:**
        * Na interface do pgAdmin, clique em "Add New Server" ou "Register" -> "Server".
        * Na aba **General**, defina um nome como `My PostgreSQL Local`.
        * Na aba **Connection**, preencha:
            * `Host name/address`: `localhost`
            * `Port`: `5432`
            * `Maintenance database`: `ecommerce_db`
            * `Username`: `postgres`
            * `Password`: `postgres`
        * Clique em "Save".
    * **Execute o Script de Schema e Popula√ß√£o de Dados:**
        * No pgAdmin, navegue at√© o servidor rec√©m-conectado -> "Databases" -> `ecommerce_db`.
        * Abra uma "Query Tool" (√≠cone de folha com tri√¢ngulo verde).
        * Copie e cole o conte√∫do do arquivo `orderskafka/src/main/resources/data.sql` (ou o conte√∫do abaixo) na Query Tool e execute. Este script cont√©m tanto a cria√ß√£o das tabelas quanto a popula√ß√£o inicial dos produtos.
        ```sql
        -- orderskafka/src/main/resources/data.sql

        -- Remove tabelas existentes para garantir um ambiente limpo
        DROP TABLE IF EXISTS order_items;
        DROP TABLE IF EXISTS orders;
        DROP TABLE IF EXISTS products;

        -- Cria√ß√£o da tabela de produtos
        CREATE TABLE products (
                                  id UUID PRIMARY KEY,
                                  name VARCHAR(255) NOT NULL,
                                  price NUMERIC(10, 2) NOT NULL,
                                  quantity INT NOT NULL
        );

        -- Cria√ß√£o da tabela de pedidos
        CREATE TABLE orders (
                                id UUID PRIMARY KEY,
                                customer_name VARCHAR(255) NOT NULL,
                                created_at TIMESTAMP WITH TIME ZONE NOT NULL
        );

        -- Cria√ß√£o da tabela de itens do pedido
        CREATE TABLE order_items (
                                     id BIGSERIAL PRIMARY KEY,
                                     order_id UUID NOT NULL REFERENCES orders(id),
                                     product_id UUID NOT NULL,
                                     product_name VARCHAR(255) NOT NULL,
                                     quantity INT NOT NULL,
                                     unit_price NUMERIC(10, 2) NOT NULL
        );

        -- Inserir alguns produtos de exemplo
        INSERT INTO products (id, name, price, quantity) VALUES
                                                             ('a0eebc99-9c0b-4ef8-bb6d-6bb9bd380a11', 'Laptop Gamer Ultra', 7500.00, 10),
                                                             ('a0eebc99-9c0b-4ef8-bb6d-6bb9bd380a12', 'Mouse Sem Fio Fast', 150.50, 50),
                                                             ('a0eebc99-9c0b-4ef8-bb6d-6bb9bd380a13', 'Teclado Mec√¢nico RGB', 450.00, 30),
                                                             ('a0eebc99-9c0b-4ef8-bb6d-6bb9bd380a14', 'Monitor 4K 27"', 2200.00, 15);
        ```

4.  **Crie os T√≥picos Kafka:**
    Entre no cont√™iner Kafka e crie os t√≥picos necess√°rios.
    ```bash
    sudo docker exec -it kafka bash
    kafka-topics --bootstrap-server kafka:29092 --create --topic orders --partitions 1 --replication-factor 1
    kafka-topics --bootstrap-server kafka:29092 --create --topic inventory-events --partitions 1 --replication-factor 1
    kafka-topics --bootstrap-server kafka:29092 --list # Para verificar se foram criados
    exit
    ```

5.  **Rode o Backend do Order-Service:**
    Na raiz do projeto (`kafka-order-processing/`), navegue at√© a pasta `orderskafka/` e execute:
    ```bash
    cd orderskafka/
    mvn clean install
    mvn spring-boot:run
    ```
    O servi√ßo estar√° rodando na porta `8080`. Aguarde a mensagem `Started OrderskafkaApplication...` nos logs.

6.  **Rode o Backend do Inventory-Service:**
    Abra um **novo terminal**. Na raiz do projeto (`kafka-order-processing/`), navegue at√© a pasta `inventory-service/` e execute:
    ```bash
    cd inventory-service/
    mvn clean install
    mvn spring-boot:run
    ```
    O servi√ßo estar√° rodando na porta `8081`. Aguarde a mensagem `Started InventoryServiceApplication...` nos logs.

7.  **Rode o Backend do Notification-Service:**
    Abra um **novo terminal**. Na raiz do projeto (`kafka-order-processing/`), navegue at√© a pasta `notification-service/` e execute:
    ```bash
    cd notification-service/
    mvn clean install
    mvn spring-boot:run
    ```
    O servi√ßo estar√° rodando na porta `8083`. Aguarde a mensagem `Started NotificationServiceApplication...` nos logs.

8.  **Rode o Frontend:**
    Abra um **novo terminal**. Na raiz do projeto (`kafka-order-processing/`), navegue at√© a pasta `frontend-app/`.
    ```bash
    cd frontend-app/
    npm install
    npm run dev
    ```
    O frontend estar√° acess√≠vel (geralmente em `http://localhost:5173`, verifique o output do `npm run dev`).

### 4. Teste a Solu√ß√£o Completa:

* Abra o frontend no seu navegador (`http://localhost:5173`).
* Preencha o campo "Nome do Cliente".
* Adicione produtos ao pedido usando o "Search Select".
* Clique em "Registrar Pedido".
* **Observe:**
    * A notifica√ß√£o de sucesso/erro no frontend (pop-up do Ant Design e no card "Status das Notifica√ß√µes").
    * Os logs do seu `orderskafka` (Order-Service) para a mensagem "üì¶ Pedido enviado ao Kafka".
    * Os logs do seu `inventoryservice` (Inventory-Service) para "üì¶ Evento de Pedido Recebido no Inventory-Service".
    * Os logs do seu `notificationservice` (Notification-Service) para "üì¨ Notifica√ß√£o Recebida".
    * No Kafka UI (`http://localhost:8180`), v√° em "Topics", clique em "orders" e depois em "Messages" para ver os pedidos publicados. Fa√ßa o mesmo para "inventory-events".

---

## 5. Requisitos N√£o-Funcionais (RNFs)

### 1. Escalabilidade

**Conceito:** A escalabilidade √© a capacidade de um sistema lidar com um aumento na carga de trabalho ou demanda, adicionando recursos (hardware, software) sem comprometer o desempenho ou a funcionalidade.

**Como o Apache Kafka Consegue Escalabilidade:**

* **Parti√ß√µes (Partitions):** Os t√≥picos no Kafka s√£o divididos em parti√ß√µes. Cada parti√ß√£o √© uma sequ√™ncia de mensagens ordenada e imut√°vel. As parti√ß√µes permitem que os dados sejam distribu√≠dos entre v√°rios brokers (servidores Kafka) e que os consumidores de um grupo de consumidores leiam dados em paralelo. Adicionar mais parti√ß√µes a um t√≥pico permite um maior paralelismo de leitura e escrita.
* **Consumidores Paralelos (Consumer Groups):** Um grupo de consumidores pode ler de um t√≥pico, onde cada consumidor no grupo l√™ de um subconjunto de parti√ß√µes. Adicionar mais inst√¢ncias de consumidores a um grupo aumenta a taxa de processamento, pois eles processam parti√ß√µes em paralelo, cada um respons√°vel por um conjunto exclusivo de parti√ß√µes dentro do grupo.
* **Adi√ß√£o Horizontal de Brokers:** √â f√°cil adicionar novos brokers a um cluster Kafka em execu√ß√£o. Quando novos brokers s√£o adicionados, as parti√ß√µes existentes podem ser rebalanceadas para esses novos brokers, distribuindo a carga de armazenamento e processamento entre mais m√°quinas. Isso permite aumentar a capacidade de throughput e armazenamento do cluster.
* **Armazenamento Distribu√≠do:** As mensagens s√£o persistidas em disco nos brokers de forma distribu√≠da, e o Kafka √© projetado para lidar com grandes volumes de dados de forma eficiente. Isso permite que a taxa de dados de entrada exceda a taxa de dados de sa√≠da momentaneamente (armazenamento em buffer) sem perda de dados, mantendo a robustez do sistema sob picos de carga.

### 2. Toler√¢ncia √† Falha

**Conceito:** Toler√¢ncia √† falha √© a propriedade de um sistema continuar operando corretamente e sem interrup√ß√µes significativas mesmo na ocorr√™ncia de falhas em um ou mais de seus componentes.

**Como o Apache Kafka Trata a Falha:**

* **Replica√ß√£o de Dados (Replication Factor):** No Kafka, cada parti√ß√£o pode ter m√∫ltiplas r√©plicas (`replication-factor`). Uma dessas r√©plicas √© designada como "l√≠der" (leader) e as outras s√£o "seguidoras" (followers). Todos os produtores escrevem para o l√≠der, e todos os consumidores leem do l√≠der. As r√©plicas seguidoras replicam continuamente os dados do l√≠der.
* **Elei√ß√£o Autom√°tica de L√≠der:** Se o broker que hospeda a parti√ß√£o l√≠der falhar, o Kafka (historicamente com a ajuda do ZooKeeper, ou mais recentemente, o pr√≥prio Kafka com o processo de `KRaft` que substitui o ZooKeeper para gest√£o de metadata) automaticamente elege uma das r√©plicas seguidoras que est√£o em sincronia com o l√≠der falho como o novo l√≠der. Isso acontece de forma transparente para produtores e consumidores (ap√≥s um breve per√≠odo de recupera√ß√£o).
* **Persist√™ncia em Disco:** As mensagens s√£o duravelmente persistidas em disco nos brokers e s√£o replicadas, minimizando a perda de dados mesmo em caso de falha de hardware ou rede.
* **Rebalanceamento Autom√°tico de Consumidores:** Se um consumidor em um grupo de consumidores falhar, as parti√ß√µes que ele estava consumindo s√£o automaticamente reatribu√≠das a outros consumidores ativos no mesmo grupo. Isso garante que o processamento continue e que todas as parti√ß√µes continuem sendo lidas.

**Exemplo de Situa√ß√£o de Falha e Tratamento:**

* **Situa√ß√£o de Falha:** Um dos servidores (brokers) do seu cluster Kafka desliga inesperadamente (ex: falha de hardware, queda de energia na m√°quina do broker).
* **Como o Kafka Trata:**
    1.  As parti√ß√µes l√≠deres que estavam sendo hospedadas nesse broker falho se tornam indispon√≠veis temporariamente.
    2.  O Kafka, atrav√©s do seu mecanismo de coordena√ß√£o, detecta a falha do broker.
    3.  Para cada parti√ß√£o que perdeu seu l√≠der, uma nova elei√ß√£o de l√≠der √© iniciada. Uma das r√©plicas seguidoras restantes (que j√° possui uma c√≥pia id√™ntica e em sincronia dos dados) √© promovida a novo l√≠der.
    4.  Produtores e consumidores que estavam interagindo com o l√≠der falho s√£o automaticamente redirecionados para o novo l√≠der da parti√ß√£o.
    5.  O fluxo de dados continua com uma interrup√ß√£o m√≠nima e controlada, e nenhum dado √© perdido, pois ele j√° estava replicado e dispon√≠vel em outras r√©plicas.

### 3. Idempot√™ncia

**Conceito:** A idempot√™ncia, em sistemas distribu√≠dos, significa que uma opera√ß√£o pode ser executada m√∫ltiplas vezes, mas produzir√° o mesmo resultado (ou efeito final) como se tivesse sido executada apenas uma √∫nica vez. Ou seja, repetir uma opera√ß√£o idempotente n√£o causa efeitos colaterais adicionais ou inconsist√™ncias no estado do sistema.

**Como Garantir Idempot√™ncia no Kafka:**

O Kafka oferece garantias de idempot√™ncia para produtores e, em conjunto com outras estrat√©gias, permite o processamento "exactly-once" (processar cada mensagem exatamente uma vez) para consumidores.

* **Idempot√™ncia do Produtor (`enable.idempotence=true`):**
    * No Kafka (a partir da vers√£o 0.11), os produtores podem ser configurados para serem **idempotentes** ao definir a propriedade `enable.idempotence=true`.
    * Quando ativada, o broker Kafka atribui um ID de produtor (Producer ID) e um n√∫mero de sequ√™ncia (Sequence Number) a cada lote de mensagens enviado. Se uma mensagem for enviada novamente (por exemplo, devido a uma falha de rede tempor√°ria e uma retransmiss√£o autom√°tica do produtor), o broker usa esses IDs para detectar e descartar duplicatas, garantindo que a mensagem seja escrita no log da parti√ß√£o apenas uma vez.
    * **Implementa√ß√£o:** No seu `application.properties` do servi√ßo produtor (Order-Service, Inventory-Service):
        ```properties
        spring.kafka.producer.properties.enable.idempotence=true
        ```

* **Idempot√™ncia do Consumidor (Processamento "Exactly-Once" com Transa√ß√µes ou L√≥gica de Aplica√ß√£o):**
    * Garantir que os *consumidores* processem uma mensagem exatamente uma vez √© mais complexo, pois envolve o consumo, o processamento da l√≥gica de neg√≥cio e a atualiza√ß√£o de um estado (como um banco de dados ou outra grava√ß√£o em Kafka).
    * **Transa√ß√µes At√¥micas no Kafka:** O Kafka oferece suporte a transa√ß√µes at√¥micas de ponta a ponta. Isso permite que um consumidor/produtor (tamb√©m conhecido como "stream processor") consuma mensagens de t√≥picos de entrada, execute processamento e produza mensagens para t√≥picos de sa√≠da (ou atualize um banco de dados) como uma √∫nica opera√ß√£o at√¥mica. Se a transa√ß√£o falhar, todas as altera√ß√µes s√£o revertidas (rollback), evitando duplicatas ou estados inconsistentes. Isso √© ativado usando `spring.kafka.producer.transaction-id-prefix` e `KafkaTransactionManager` no Spring Kafka.
    * **Idempot√™ncia no N√≠vel da Aplica√ß√£o:** Para opera√ß√µes que atualizam um banco de dados ou outros sistemas externos, a l√≥gica de neg√≥cio do consumidor deve ser projetada para ser **idempotente**. Isso significa que a opera√ß√£o de atualiza√ß√£o deve produzir o mesmo resultado mesmo se executada v√°rias vezes. Exemplos incluem:
        * **UPSERT:** Utilizar opera√ß√µes que inserem um registro se ele n√£o existe ou atualizam-no se j√° existe.
        * **Verifica√ß√£o de Duplicatas:** Antes de executar uma opera√ß√£o, verificar se ela j√° foi realizada usando um ID de idempot√™ncia (por exemplo, o `orderId` da mensagem Kafka).
        * **IDs de Idempot√™ncia:** Incluir um ID √∫nico de idempot√™ncia na mensagem ou na requisi√ß√£o, e o sistema receptor usa esse ID para garantir que a opera√ß√£o seja processada apenas uma vez.

Ao combinar a idempot√™ncia do produtor do Kafka com a idempot√™ncia no n√≠vel da aplica√ß√£o (para as opera√ß√µes de consumidor que modificam estado) e, quando necess√°rio, as transa√ß√µes transacionais do Kafka, √© poss√≠vel alcan√ßar um processamento robusto e sem duplicatas.
